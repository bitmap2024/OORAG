
'''
# 适合完整长文章问答
1. 文本分块：
2. 将长文本分割成较短的连续文本块。如果句子长度超过预设的标记限制（例如100个标记），则整个句子将被移动到下一个文本块。
生成初始嵌入：
3. 使用SBERT这类基于BERT的编码器为每个文本块生成嵌入向量，这些向量能够捕捉文本的语义信息。
聚类文本块：
4. 利用聚类算法（如高斯混合模型GMMs）对文本块的嵌入向量进行聚类，将语义相似的文本块分组在一起。
软聚类：
5. 通过软聚类，文本块可以属于多个聚类，这允许一个文本块在多个主题的摘要中出现。
降维处理：
6. 使用UMAP这类降维技术来处理高维嵌入向量，以改善聚类效果。
生成文本摘要：
7. 对每个聚类中的文本块使用语言模型进行摘要，生成包含关键信息的文本摘要。
递归构建树结构：
8. 将上一步生成的摘要文本再次进行嵌入和聚类，形成更高层次的聚类和摘要，这个过程递归进行，直到达到所需的抽象层次或聚类不再可行。
构建树的层级：
9. 树的每个节点包含文本摘要，子节点是较低层次的摘要，而父节点是较高层次的摘要。这样，树的根节点将包含整个文本的最高层次的概述。
查询和检索：
10. 在接收到查询时，RAPTOR通过树遍历或折叠树的方法检索信息。树遍历从顶层开始，逐层深入到更具体的摘要；折叠树则将所有节点放在同一层次上，根据与查询的相关性进行检索。
整合检索结果：
根据检索策略，选择与查询最相关的节点，并将这些节点的文本摘要整合起来，形成对查询的响应。

对10的详细介绍，检索过程：
当文档树结构构建完成后，RAPTOR的检索过程如下：

1. **接收查询**：
   - 用户提出一个问题或一个查询请求。

2. **查询嵌入**：
   - 使用与构建树时相同的嵌入技术（如SBERT）将用户查询转换成嵌入向量。

3. **选择检索策略**：
   - 根据需求选择检索策略，可以是树遍历（traverse the tree layer by layer）或折叠树（collapsed tree approach）。

4. **树遍历检索**：
   - 如果选择树遍历，从树的顶层开始，计算查询向量与每个节点嵌入向量的余弦相似度。
   - 选择与查询最相关的k个节点，然后移动到下一层，重复此过程，直到达到叶节点或所需层次。

5. **折叠树检索**：
   - 如果选择折叠树，首先将整个树结构展平为单一层次，忽略树的层次结构。
   - 计算查询向量与所有节点嵌入向量的余弦相似度，并选择最相关的k个节点。

6. **节点选择**：
   - 根据相似度分数，选择最相关的节点。在树遍历中，这是逐层进行的；在折叠树中，这是一次性完成的。

7. **信息整合**：
   - 将选定的节点文本进行整合。在树遍历中，这可能意味着整合来自不同层级的节点；在折叠树中，整合的是来自整个树中选出的节点。

8. **生成响应**：
   - 使用整合的文本作为上下文，输入到语言模型中，生成对用户查询的响应。

9. **优化和调整**：
   - 根据检索结果的质量，可能需要调整检索策略，比如改变k值或调整嵌入参数。

**例子**：
假设我们有一个关于科学论文的长文档，并且已经使用RAPTOR构建了文档的树形结构。用户提出了一个问题：“这篇论文的主要贡献是什么？”

1. **查询嵌入**：
   - 将问题转换成嵌入向量。

2. **检索**：
   - 使用折叠树检索策略，计算问题嵌入向量与树中所有节点嵌入向量的余弦相似度。

3. **节点选择**：
   - 选择最相关的k个节点，这些节点可能包括了摘要、关键实验结果或结论部分的文本摘要。

4. **信息整合**：
   - 将这些节点的文本摘要整合在一起，形成一个全面的上下文。

5. **生成响应**：
   - 将整合的上下文输入到语言模型，模型根据这个上下文生成对“主要贡献”的回答。

6. **优化**：
   - 如果回答不够全面或准确，可能需要调整k值，或者使用树遍历策略来获取更深层次的信息。
通过这个过程，RAPTOR能够有效地从长文档中检索和整合信息，以回答用户的复杂查询。

'''

